{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarisation with Text-to-Text Transfer Transformer (T5) Model\n",
    "\n",
    "## 1.0. Introduction\n",
    "\n",
    "In today's digital age, news flows in an endless stream from various sources. We have great amount of news articles everyday. But, there are a small amount of useful information in the articles and it is hard to extract useful information manually. As a result, there are lots of news articles but, it is hard to read all of articles and find informative news manually. One of the solutions for this problem is to summarize texts in the article.\n",
    "\n",
    "<p align='center'>\n",
    "    <img src=\"https://blog.fpt-software.com/hs-fs/hubfs/image-8.png?width=376&name=image-8.png\" alt=\"Text Summarisation Visual\" />\n",
    "</p>\n",
    "\n",
    "### 1.1. Problem Statement\n",
    "Text summarisation automatically gives the reader a summary containing important sentences and relevant information about an article. This is highly useful because it shortens the time needed to capture the meaning and main events of an article. Broadly, there are 2 ways of performing text summarisation - abstractive and extractive. \n",
    "\n",
    "**Abstractive.** Abstractive methods analyse input texts and generate new texts that capture the essence of the original text. If trained correctly, they convey the same meaning as the original text, yet are more concise.\n",
    "\n",
    "**Extractive.** Extractive methods, on the other, take out the important texts from the original text and joins them to form a summary. Hence, they do not generate any new texts.\n",
    "\n",
    "In this assignment, we'll use the abstractive method to solve the following problem - **given a news article, can we return a succinct summary of the article?**\n",
    "\n",
    "### 1.2. Abstractive Text Summarisation\n",
    "Abstractive text summarisation can be achieved with transformer models. Specifically, we will apply transfer learning from pre-trained models that will be fine tuned on a downstream task. \n",
    "\n",
    "Transfer learning, in the context of transformers, are very helpful in improving model performances. Fortunately, there are available pre-trained transformers that are available to be used. Notable examples include the Bi-Directional Encoder Representations from Transformers (BERT), and Text-to-Text Transfer Transformer (T5). For our assignment, we will use the T5 model. It is an encoder-decoder model that's been pre-trained on multiple types of tasks. As a result, it works well on a variety of tasks. \n",
    "\n",
    "But, before we implement our pre-trained T5 model, we will want to fine-tune it with a supervised task of reading news articles as inputs and training them against their respective authored news summaries. Fortunately, there are available data sets that offer such news summarisation, e.g. CNN+Dailynews, and XSum. By fine tuning the model, we ensure that the model is better trained for our given task of extracting a succinct summary from news articles. **We'll be using XSum.** \n",
    "\n",
    "**Why do we use the XSum dataset?** XSum stands for 'Extreme Summarisation' and it is a dataset for evaluating single-document summarisation systems. Each article summary follows the question of 'What is the article about?'. It comprises of 226,711 news articles accompanied with one-sentence summary, and they are collected from BBC (from 2010 to 2017) which cover a wide variety of genres such as general news, politics, sports, weather, business, technology, science, health, family, education, entertainment and arts. With a wide span of genre, it is the ideal dataset to use for our pre-trained models fine tuning exercise.\n",
    "\n",
    "### 1.3. Environment\n",
    "AWS EC2 Instance - Deep Learning AMI GPU TensorFlow 2.7.3 (Ubuntu 20.04). Instance type: c5.2xlarge\n",
    "\n",
    "(Learn how to set up your deep learning workstation with AWS [here](https://medium.com/@bobbycxy/detailed-guide-to-connect-ec2-with-vscode-2c084c265e36?source=your_stories_page))\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## 2.0. Data Preprocessing\n",
    "### 2.1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 08:29:04.189021: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-25 08:29:05.494473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "## import the needed libraries\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Only log error messages\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Prepare Key Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of the dataset to split as train and test\n",
    "TRAIN_TEST_SPLIT = 0.1\n",
    "\n",
    "# Training Parameters\n",
    "MAX_INPUT_LENGTH = 1024  # Maximum length of the input to the model\n",
    "BATCH_SIZE = 8  # Batch-size for training our model\n",
    "LEARNING_RATE = 2e-5  # Learning-rate for training our model\n",
    "MAX_EPOCHS = 1  # Maximum number of epochs we will train the model for\n",
    "\n",
    "# Inference Parameters\n",
    "MIN_TARGET_LENGTH = 5  # Minimum length of the output by the model\n",
    "MAX_TARGET_LENGTH = 128  # Maximum length of the output by the model\n",
    "\n",
    "# What type of model? We'll use the t5-small\n",
    "MODEL = \"t5-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Import Data\n",
    "As mentioned in Section 1.1., we will use the XSum dataset. This dataset is available with huggingface's datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"xsum\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll explore how the dataset holds the article text and the article summary. We'll learn that the dataset holds the data in a tidy fashion that allows us to read and get the data easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCUMENT:\n",
      " The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\n",
      "Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\n",
      "Trains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\n",
      "Many businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\n",
      "First Minister Nicola Sturgeon visited the area to inspect the damage.\n",
      "The waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\n",
      "Jeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\n",
      "However, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\n",
      "\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\n",
      "\"That may not be true but it is perhaps my perspective over the last few days.\n",
      "\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\n",
      "Meanwhile, a flood alert remains in place across the Borders because of the constant rain.\n",
      "Peebles was badly hit by problems, sparking calls to introduce more defences in the area.\n",
      "Scottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\n",
      "The Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\n",
      "He said it was important to get the flood protection plan right but backed calls to speed up the process.\n",
      "\"I was quite taken aback by the amount of damage that has been done,\" he said.\n",
      "\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\n",
      "He said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\n",
      "Have you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.\n",
      "----------------------------------\n",
      "SUMMARY:\n",
      " Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.\n",
      "----------------------------------\n",
      "Number of observations 204045\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = [doc for doc in raw_datasets]\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "i = 0\n",
    "\n",
    "print(\"DOCUMENT:\\n\", df.loc[i,'document'])\n",
    "print('----------------------------------')\n",
    "print(\"SUMMARY:\\n\", df.loc[i,'summary'])\n",
    "print('----------------------------------')\n",
    "print(\"Number of observations\",len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we proceed to take a small stratified sampling of the train and test data. By taking a stratified sampling, we ensure a balanced mix of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = raw_datasets.train_test_split(\n",
    "    train_size=TRAIN_TEST_SPLIT, test_size=TRAIN_TEST_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our model, we need to pre-process our inputs. A key step is tokenising the inputs, as well as converting these strings into their respective IDs. We can do this easily by taking a pre-trained tokenizer from the Hugging Face Model Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [363, 405, 3, 9, 14145, 8585, 3735, 1205, 116, 25, 3305, 34, 3, 9, 6108, 58, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what does the tokenizer return?\n",
    "## it returns a dictionary of 2 keys - input ids, and the attention mask.\n",
    "\n",
    "tokenizer('What does a tokenizer object return when you feed it a string?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** When using T5, we should place a prefix titled 'summarize' in the inputs. If the model is meant for translation, then we'll adjust our prefix accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL in [\"t5-small\", \"t5-base\", \"t5-large\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Helper Function\n",
    "\n",
    "Here, we want to have a function to pre-process the huggingface data. Concretely, we want it to tokenise the inputs and the targets, and return a dictionary of keys - input_ids, attention_mask and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    # tokenise inputs\n",
    "    inputs = [prefix + doc for doc in examples[\"document\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True)\n",
    "\n",
    "    # tokenise targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"summary\"], max_length=MAX_TARGET_LENGTH, truncation=True\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/20404 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20404/20404 [00:31<00:00, 643.21 examples/s]\n",
      "Map: 100%|██████████| 20405/20405 [00:31<00:00, 637.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The 22-year-old was part of the England Under-...</td>\n",
       "      <td>Watford have signed midfielder Nathaniel Chalo...</td>\n",
       "      <td>40603257</td>\n",
       "      <td>[21603, 10, 37, 1630, 18, 1201, 18, 1490, 47, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3129, 17, 2590, 43, 3814, 2076, 1846, 49, 180...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Garcia started slowly but controlled the later...</td>\n",
       "      <td>Danny Garcia won the vacant WBC welterweight t...</td>\n",
       "      <td>35394450</td>\n",
       "      <td>[21603, 10, 22373, 708, 5665, 68, 6478, 8, 865...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[19445, 22373, 751, 8, 14333, 549, 7645, 3, 93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samuel Hertz will spend a year working to crea...</td>\n",
       "      <td>A composer who plans to create a work of music...</td>\n",
       "      <td>38962932</td>\n",
       "      <td>[21603, 10, 15718, 216, 25075, 56, 1492, 3, 9,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[71, 13075, 113, 1390, 12, 482, 3, 9, 161, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The message from Craig was displayed for Linsa...</td>\n",
       "      <td>A couple are getting hitched after a proposal ...</td>\n",
       "      <td>39337294</td>\n",
       "      <td>[21603, 10, 37, 1569, 45, 12870, 47, 6099, 21,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[71, 1158, 33, 652, 1560, 4513, 227, 3, 9, 638...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Property owners maintain that cracks appearing...</td>\n",
       "      <td>Residents in part of Swindon have said they fe...</td>\n",
       "      <td>26291708</td>\n",
       "      <td>[21603, 10, 8648, 2713, 1961, 24, 5261, 7, 160...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[24998, 16, 294, 13, 180, 5165, 106, 43, 243, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  The 22-year-old was part of the England Under-...   \n",
       "1  Garcia started slowly but controlled the later...   \n",
       "2  Samuel Hertz will spend a year working to crea...   \n",
       "3  The message from Craig was displayed for Linsa...   \n",
       "4  Property owners maintain that cracks appearing...   \n",
       "\n",
       "                                             summary        id  \\\n",
       "0  Watford have signed midfielder Nathaniel Chalo...  40603257   \n",
       "1  Danny Garcia won the vacant WBC welterweight t...  35394450   \n",
       "2  A composer who plans to create a work of music...  38962932   \n",
       "3  A couple are getting hitched after a proposal ...  39337294   \n",
       "4  Residents in part of Swindon have said they fe...  26291708   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [21603, 10, 37, 1630, 18, 1201, 18, 1490, 47, ...   \n",
       "1  [21603, 10, 22373, 708, 5665, 68, 6478, 8, 865...   \n",
       "2  [21603, 10, 15718, 216, 25075, 56, 1492, 3, 9,...   \n",
       "3  [21603, 10, 37, 1569, 45, 12870, 47, 6099, 21,...   \n",
       "4  [21603, 10, 8648, 2713, 1961, 24, 5261, 7, 160...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [3129, 17, 2590, 43, 3814, 2076, 1846, 49, 180...  \n",
       "1  [19445, 22373, 751, 8, 14333, 549, 7645, 3, 93...  \n",
       "2  [71, 13075, 113, 1390, 12, 482, 3, 9, 161, 13,...  \n",
       "3  [71, 1158, 33, 652, 1560, 4513, 227, 3, 9, 638...  \n",
       "4  [24998, 16, 294, 13, 180, 5165, 106, 43, 243, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = [doc for doc in tokenized_datasets['train']]\n",
    "train_df = pd.DataFrame(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto Classes help users to retrieve relevant models in an intuitive manner. In addition, our text summarisation fine tuning exercise involves the use of sequences for the input and the output. Hence, we'll want to use the TFAutoModelForSeq2SeqLM. Loading model weights is simple with the '.from_pretrained()' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 14:43:40.504782: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important step is padding our inputs. That's so that each all inputs and targets share the same length. To achieve this efficiently, we can use the DataCollatorForSeq2Seq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can prepare the train and test dataset. The generation dataset is what we'll use to calculate our evaluation metric score when the model is training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "## to calculate our ROUGE score\n",
    "generation_dataset = (\n",
    "    tokenized_datasets[\"test\"].shuffle().select(list(range(200))).to_tf_dataset(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0. Compiling and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll use the ROUGE-L metric for our evaluation of the model. The Rouge-L metric is a score from 0 to 1 indicating how similar two sequences are, based on the length of the longest common subsequence (LCS). In particular, Rouge-L is the weighted harmonic mean (or f-measure) combining the LCS precision (the percentage of the hypothesis sequence covered by the LCS) and the LCS recall (the percentage of the reference sequence covered by the LCS). For more information, use this [link](https://www.tensorflow.org/text/tutorials/text_similarity#rouge-l)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nlp\n",
    "\n",
    "rouge_l = keras_nlp.metrics.RougeL()\n",
    "\n",
    "\n",
    "def metric_fn(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    for label in labels:\n",
    "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge_l(decoded_labels, decoded_predictions)\n",
    "    # We will print only the F1 score, you can use other aggregation metrics as well\n",
    "    result = {\"RougeL\": result[\"f1_score\"]}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No label_cols specified for KerasMetricCallback, assuming you want the 'labels' key.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2551/2551 [==============================] - 20455s 8s/step - loss: 2.9282 - val_loss: 2.5907 - RougeL: 0.1884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7faa649978b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn, eval_dataset=generation_dataset, predict_with_generate=True\n",
    ")\n",
    "\n",
    "callbacks = [metric_callback]\n",
    "\n",
    "# For now we will use our test set as our validation_data\n",
    "model.fit(\n",
    "    train_dataset, validation_data=test_dataset, epochs=MAX_EPOCHS, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2551/2551 [==============================] - 20445s 8s/step - loss: 2.7848 - val_loss: 2.5422 - RougeL: 0.1939\n",
      "Epoch 2/2\n",
      "2551/2551 [==============================] - 20551s 8s/step - loss: 2.7261 - val_loss: 2.5153 - RougeL: 0.1963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7faa6503ddf0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, validation_data=test_dataset, epochs=2, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Save the Model and Tokenizer for reusing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5_xsum_trained_model_ec2_tokenizer/tokenizer_config.json',\n",
       " 't5_xsum_trained_model_ec2_tokenizer/special_tokens_map.json',\n",
       " 't5_xsum_trained_model_ec2_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save the model and tokenizer\n",
    "model.save_pretrained(\"t5_xsum_trained_model_ec2\", from_pt=True)\n",
    "tokenizer.save_pretrained(\"t5_xsum_trained_model_ec2_tokenizer\", from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0. Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Prince has been visiting Queen's University's cyber security unit at the  Science Park in Belfast's Titanic Quarter.\n",
      "Among the cyber security on show is a system that prevents hackers from accessing water and electricity supplies.\n",
      "Prince Charles will be joined by the Duchess of Cornwall on Tuesday.\n",
      "Among those who met Prince Charles during his visit to the cyber security unit were First Minister Arlene Foster, East Belfast MP Gavin Robinson and Deputy Lord Mayor Guy Spence.\n",
      "The Prince was accompanied by Lord Lieutenant Fionnuala Jay O'Boyle and Secretary of State Theresa Villiers.\n",
      "----------------------------------------------------------------\n",
      "Prince Charles will be joined by the Duchess of Cornwall on a visit to the Queen's University cyber security unit.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, framework=\"tf\")\n",
    "\n",
    "index = 0\n",
    "print(raw_datasets[\"test\"][index][\"document\"])\n",
    "print('----------------------------------------------------------------')\n",
    "\n",
    "result = summarizer(raw_datasets[\"test\"][index][\"document\"],\n",
    "                    min_length=MIN_TARGET_LENGTH,\n",
    "                    max_length=MAX_TARGET_LENGTH)\n",
    "\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Test it Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGAPORE – In an attempt to evade arrest, a doctor who drove a car after drinking beer tried to change seats with his passenger when he spotted a police roadblock.\n",
      "\n",
      "The passenger refused to do so and Nah Kwang Meng, who practises at Dr Nah & Lee Family Clinic in Woodlands, initially failed a breathalyser test after he stepped out of the vehicle.\n",
      "\n",
      "He was later found to have 32 micrograms (mcg) of alcohol in 100ml of breath – below the prescribed legal limit of 35mcg.\n",
      "\n",
      "Even though he had not been drink driving, Nah, 41, was fined $4,000 on Friday after he pleaded guilty to one count of attempting to perform an act that could pervert the course of justice.\n",
      "\n",
      "Assistant Public Prosecutor Chye Jer Yuan told the court that before going behind the wheel on July 14, 2022, Nah had dinner and consumed about three to four glasses of beer.\n",
      "\n",
      "He was driving along Sophia Road towards Upper Wilkie Road shortly before 11.30pm when he spotted a police roadblock.\n",
      "\n",
      "The prosecutor said: “The accused requested his front-seat passenger to swop seats with him, so that he would not be presented as the driver of the vehicle at the roadblock.\n",
      "----------------------------------------------------------------\n",
      "A doctor who drove a car after drinking beer has been fined $4,000 after he pleaded guilty to attempting to pervert the course of justice.\n"
     ]
    }
   ],
   "source": [
    "text_to_summarise = \"\"\"SINGAPORE – In an attempt to evade arrest, a doctor who drove a car after drinking beer tried to change seats with his passenger when he spotted a police roadblock.\n",
    "\n",
    "The passenger refused to do so and Nah Kwang Meng, who practises at Dr Nah & Lee Family Clinic in Woodlands, initially failed a breathalyser test after he stepped out of the vehicle.\n",
    "\n",
    "He was later found to have 32 micrograms (mcg) of alcohol in 100ml of breath – below the prescribed legal limit of 35mcg.\n",
    "\n",
    "Even though he had not been drink driving, Nah, 41, was fined $4,000 on Friday after he pleaded guilty to one count of attempting to perform an act that could pervert the course of justice.\n",
    "\n",
    "Assistant Public Prosecutor Chye Jer Yuan told the court that before going behind the wheel on July 14, 2022, Nah had dinner and consumed about three to four glasses of beer.\n",
    "\n",
    "He was driving along Sophia Road towards Upper Wilkie Road shortly before 11.30pm when he spotted a police roadblock.\n",
    "\n",
    "The prosecutor said: “The accused requested his front-seat passenger to swop seats with him, so that he would not be presented as the driver of the vehicle at the roadblock.\"\"\"\n",
    "\n",
    "print(text_to_summarise)\n",
    "print('----------------------------------------------------------------')\n",
    "\n",
    "result = summarizer(text_to_summarise,\n",
    "                    min_length=MIN_TARGET_LENGTH,\n",
    "                    max_length=MAX_TARGET_LENGTH)\n",
    "\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oct 19 (Reuters) - Three Palestinians, including two teenagers, were killed by Israeli forces in separate incidents in the occupied West Bank early on Thursday, Palestinian official news agency WAFA said.\n",
      "\n",
      "Israeli forces stormed the village of Budrus, west of Ramallah, shooting dead a young man, Gebriel Awad, and wounding another, WAFA said.\n",
      "\n",
      "In other incidents, a 14-year-old was killed by a bullet wound in the head in a refugee camp south of Bethlehem and a 16-year-old succumbed to his wounds after being shot in the town of Tulkarm, the news agency added.\n",
      "\n",
      "There was no immediate comment from Israel.\n",
      "\n",
      "Dozens of Palestinians have been killed in the West Bank in the latest flare-up of Israeli-Palestinian violence.\n",
      "\n",
      "Israel is preparing a ground assault in the Gaza Strip in response to a deadly attack by Palestinian militant group Hamas that killed at least 1,400 Israelis, mostly civilians, on Oct. 7.\n",
      "\n",
      "Israeli forces have carried out their fiercest bombardment of Gaza in response, killing more than 3,000 Palestinians and imposing a total siege on the blockaded enclave that Hamas controls, fuelling anger among Palestinians in the West Bank.\n",
      "----------------------------------------------------------------\n",
      "Israeli forces have killed three Palestinians, including two teenagers, in separate incidents in the West Bank, a news agency has said.\n"
     ]
    }
   ],
   "source": [
    "text_to_summarise = \"\"\"Oct 19 (Reuters) - Three Palestinians, including two teenagers, were killed by Israeli forces in separate incidents in the occupied West Bank early on Thursday, Palestinian official news agency WAFA said.\n",
    "\n",
    "Israeli forces stormed the village of Budrus, west of Ramallah, shooting dead a young man, Gebriel Awad, and wounding another, WAFA said.\n",
    "\n",
    "In other incidents, a 14-year-old was killed by a bullet wound in the head in a refugee camp south of Bethlehem and a 16-year-old succumbed to his wounds after being shot in the town of Tulkarm, the news agency added.\n",
    "\n",
    "There was no immediate comment from Israel.\n",
    "\n",
    "Dozens of Palestinians have been killed in the West Bank in the latest flare-up of Israeli-Palestinian violence.\n",
    "\n",
    "Israel is preparing a ground assault in the Gaza Strip in response to a deadly attack by Palestinian militant group Hamas that killed at least 1,400 Israelis, mostly civilians, on Oct. 7.\n",
    "\n",
    "Israeli forces have carried out their fiercest bombardment of Gaza in response, killing more than 3,000 Palestinians and imposing a total siege on the blockaded enclave that Hamas controls, fuelling anger among Palestinians in the West Bank.\"\"\"\n",
    "\n",
    "print(text_to_summarise)\n",
    "print('----------------------------------------------------------------')\n",
    "\n",
    "result = summarizer(text_to_summarise,\n",
    "                    min_length=MIN_TARGET_LENGTH,\n",
    "                    max_length=MAX_TARGET_LENGTH)\n",
    "\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get ready to look perfect as you're thinking out loud on Feb 16, 2024 at Ed Sheeran's concert. The Grammy Award-winning singer is heading to Singapore for a one-night show at the National Stadium. Plus, he's bringing along English singer Calum Scott as a guest.\n",
      "\n",
      "Tickets for the concert will cost between S$88 and S$488 and can be purchased via Ticketmaster and at SingPost outlets.\n",
      "\n",
      "If you signed up for a UOB card for Taylor Swift's concert and didn't cancel your membership afterward, here's some great news. UOB cardholders can enjoy a presale from 10am on Oct 27 till 9.59 am on Oct 29.\n",
      "\n",
      "A second presale will be held for KrisFlyer members from 10am on Oct 30 to 9.59am on Oct 31. To get in on this presale, KrisFlyer UOB credit and debit cardholders will need to subscribe to receive KrisFlyer and SIA Group promotional emails via their KrisFlyer account preferences. They will then receive a unique access code from KrisFlyer via email on Oct 27. \n",
      "\n",
      "Members who are not KrisFlyer UOB credit or debit cardholders can download Kris+, the SIA Group’s lifestyle rewards app and spend 150 miles between Oct 20 and 25 to redeem a unique access code. Do note that redemptions are limited to the first 110,000 customers.\n",
      "\n",
      "Alternatively, those with loads of miles to spare can opt to redeem Categories 1 to 4 concert tickets using their miles via KrisFlyer Experiences from Oct 30. Tickets from Categories 1 to 4 may be redeemed with 49,000; 38,000; 29,000 and 19,000 miles, respectively.\n",
      "\n",
      "General sale will commence from 11am on Oct 31.\n",
      "----------------------------------------------------------------\n",
      "Tickets for KrisFlyer and SIA Group's Category 1 to 4 concert tickets are to be redeemed at the end of the year.\n"
     ]
    }
   ],
   "source": [
    "text_to_summarise = \"\"\"Get ready to look perfect as you're thinking out loud on Feb 16, 2024 at Ed Sheeran's concert. The Grammy Award-winning singer is heading to Singapore for a one-night show at the National Stadium. Plus, he's bringing along English singer Calum Scott as a guest.\n",
    "\n",
    "Tickets for the concert will cost between S$88 and S$488 and can be purchased via Ticketmaster and at SingPost outlets.\n",
    "\n",
    "If you signed up for a UOB card for Taylor Swift's concert and didn't cancel your membership afterward, here's some great news. UOB cardholders can enjoy a presale from 10am on Oct 27 till 9.59 am on Oct 29.\n",
    "\n",
    "A second presale will be held for KrisFlyer members from 10am on Oct 30 to 9.59am on Oct 31. To get in on this presale, KrisFlyer UOB credit and debit cardholders will need to subscribe to receive KrisFlyer and SIA Group promotional emails via their KrisFlyer account preferences. They will then receive a unique access code from KrisFlyer via email on Oct 27. \n",
    "\n",
    "Members who are not KrisFlyer UOB credit or debit cardholders can download Kris+, the SIA Group’s lifestyle rewards app and spend 150 miles between Oct 20 and 25 to redeem a unique access code. Do note that redemptions are limited to the first 110,000 customers.\n",
    "\n",
    "Alternatively, those with loads of miles to spare can opt to redeem Categories 1 to 4 concert tickets using their miles via KrisFlyer Experiences from Oct 30. Tickets from Categories 1 to 4 may be redeemed with 49,000; 38,000; 29,000 and 19,000 miles, respectively.\n",
    "\n",
    "General sale will commence from 11am on Oct 31.\"\"\"\n",
    "\n",
    "print(text_to_summarise)\n",
    "print('----------------------------------------------------------------')\n",
    "\n",
    "result = summarizer(text_to_summarise,\n",
    "                    min_length=MIN_TARGET_LENGTH,\n",
    "                    max_length=MAX_TARGET_LENGTH)\n",
    "\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0. Loading and Inferencing from Saved Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5_xsum_trained_model_ec2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "\n",
    "model_load_inf = TFAutoModelForSeq2SeqLM.from_pretrained('t5_xsum_trained_model_ec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_load_inf = AutoTokenizer.from_pretrained('t5_xsum_trained_model_ec2_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer_load_inf = pipeline(\"summarization\", model=model_load_inf, tokenizer=tokenizer_load_inf, framework=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGAPORE – In an attempt to evade arrest, a doctor who drove a car after drinking beer tried to change seats with his passenger when he spotted a police roadblock.\n",
      "\n",
      "The passenger refused to do so and Nah Kwang Meng, who practises at Dr Nah & Lee Family Clinic in Woodlands, initially failed a breathalyser test after he stepped out of the vehicle.\n",
      "\n",
      "He was later found to have 32 micrograms (mcg) of alcohol in 100ml of breath – below the prescribed legal limit of 35mcg.\n",
      "\n",
      "Even though he had not been drink driving, Nah, 41, was fined $4,000 on Friday after he pleaded guilty to one count of attempting to perform an act that could pervert the course of justice.\n",
      "\n",
      "Assistant Public Prosecutor Chye Jer Yuan told the court that before going behind the wheel on July 14, 2022, Nah had dinner and consumed about three to four glasses of beer.\n",
      "\n",
      "He was driving along Sophia Road towards Upper Wilkie Road shortly before 11.30pm when he spotted a police roadblock.\n",
      "\n",
      "The prosecutor said: “The accused requested his front-seat passenger to swop seats with him, so that he would not be presented as the driver of the vehicle at the roadblock.\n",
      "----------------------------------------------------------------\n",
      "A doctor who drove a car after drinking beer has been fined $4,000 after he pleaded guilty to attempting to pervert the course of justice.\n"
     ]
    }
   ],
   "source": [
    "text_to_summarise = \"\"\"SINGAPORE – In an attempt to evade arrest, a doctor who drove a car after drinking beer tried to change seats with his passenger when he spotted a police roadblock.\n",
    "\n",
    "The passenger refused to do so and Nah Kwang Meng, who practises at Dr Nah & Lee Family Clinic in Woodlands, initially failed a breathalyser test after he stepped out of the vehicle.\n",
    "\n",
    "He was later found to have 32 micrograms (mcg) of alcohol in 100ml of breath – below the prescribed legal limit of 35mcg.\n",
    "\n",
    "Even though he had not been drink driving, Nah, 41, was fined $4,000 on Friday after he pleaded guilty to one count of attempting to perform an act that could pervert the course of justice.\n",
    "\n",
    "Assistant Public Prosecutor Chye Jer Yuan told the court that before going behind the wheel on July 14, 2022, Nah had dinner and consumed about three to four glasses of beer.\n",
    "\n",
    "He was driving along Sophia Road towards Upper Wilkie Road shortly before 11.30pm when he spotted a police roadblock.\n",
    "\n",
    "The prosecutor said: “The accused requested his front-seat passenger to swop seats with him, so that he would not be presented as the driver of the vehicle at the roadblock.\"\"\"\n",
    "\n",
    "print(text_to_summarise)\n",
    "print('----------------------------------------------------------------')\n",
    "\n",
    "result = summarizer_load_inf(text_to_summarise,\n",
    "                    min_length=MIN_TARGET_LENGTH,\n",
    "                    max_length=MAX_TARGET_LENGTH)\n",
    "\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oct 19 (Reuters) - Three Palestinians, including two teenagers, were killed by Israeli forces in separate incidents in the occupied West Bank early on Thursday, Palestinian official news agency WAFA said.\n",
      "\n",
      "Israeli forces stormed the village of Budrus, west of Ramallah, shooting dead a young man, Gebriel Awad, and wounding another, WAFA said.\n",
      "\n",
      "In other incidents, a 14-year-old was killed by a bullet wound in the head in a refugee camp south of Bethlehem and a 16-year-old succumbed to his wounds after being shot in the town of Tulkarm, the news agency added.\n",
      "\n",
      "There was no immediate comment from Israel.\n",
      "\n",
      "Dozens of Palestinians have been killed in the West Bank in the latest flare-up of Israeli-Palestinian violence.\n",
      "\n",
      "Israel is preparing a ground assault in the Gaza Strip in response to a deadly attack by Palestinian militant group Hamas that killed at least 1,400 Israelis, mostly civilians, on Oct. 7.\n",
      "\n",
      "Israeli forces have carried out their fiercest bombardment of Gaza in response, killing more than 3,000 Palestinians and imposing a total siege on the blockaded enclave that Hamas controls, fuelling anger among Palestinians in the West Bank.\n",
      "----------------------------------------------------------------\n",
      "Israeli forces have killed three Palestinians, including two teenagers, in separate incidents in the West Bank, a news agency has said.\n"
     ]
    }
   ],
   "source": [
    "text_to_summarise = \"\"\"Oct 19 (Reuters) - Three Palestinians, including two teenagers, were killed by Israeli forces in separate incidents in the occupied West Bank early on Thursday, Palestinian official news agency WAFA said.\n",
    "\n",
    "Israeli forces stormed the village of Budrus, west of Ramallah, shooting dead a young man, Gebriel Awad, and wounding another, WAFA said.\n",
    "\n",
    "In other incidents, a 14-year-old was killed by a bullet wound in the head in a refugee camp south of Bethlehem and a 16-year-old succumbed to his wounds after being shot in the town of Tulkarm, the news agency added.\n",
    "\n",
    "There was no immediate comment from Israel.\n",
    "\n",
    "Dozens of Palestinians have been killed in the West Bank in the latest flare-up of Israeli-Palestinian violence.\n",
    "\n",
    "Israel is preparing a ground assault in the Gaza Strip in response to a deadly attack by Palestinian militant group Hamas that killed at least 1,400 Israelis, mostly civilians, on Oct. 7.\n",
    "\n",
    "Israeli forces have carried out their fiercest bombardment of Gaza in response, killing more than 3,000 Palestinians and imposing a total siege on the blockaded enclave that Hamas controls, fuelling anger among Palestinians in the West Bank.\"\"\"\n",
    "\n",
    "print(text_to_summarise)\n",
    "print('----------------------------------------------------------------')\n",
    "\n",
    "result = summarizer_load_inf(text_to_summarise,\n",
    "                    min_length=MIN_TARGET_LENGTH,\n",
    "                    max_length=MAX_TARGET_LENGTH)\n",
    "\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get ready to look perfect as you're thinking out loud on Feb 16, 2024 at Ed Sheeran's concert. The Grammy Award-winning singer is heading to Singapore for a one-night show at the National Stadium. Plus, he's bringing along English singer Calum Scott as a guest.\n",
      "\n",
      "Tickets for the concert will cost between S$88 and S$488 and can be purchased via Ticketmaster and at SingPost outlets.\n",
      "\n",
      "If you signed up for a UOB card for Taylor Swift's concert and didn't cancel your membership afterward, here's some great news. UOB cardholders can enjoy a presale from 10am on Oct 27 till 9.59 am on Oct 29.\n",
      "\n",
      "A second presale will be held for KrisFlyer members from 10am on Oct 30 to 9.59am on Oct 31. To get in on this presale, KrisFlyer UOB credit and debit cardholders will need to subscribe to receive KrisFlyer and SIA Group promotional emails via their KrisFlyer account preferences. They will then receive a unique access code from KrisFlyer via email on Oct 27. \n",
      "\n",
      "Members who are not KrisFlyer UOB credit or debit cardholders can download Kris+, the SIA Group’s lifestyle rewards app and spend 150 miles between Oct 20 and 25 to redeem a unique access code. Do note that redemptions are limited to the first 110,000 customers.\n",
      "\n",
      "Alternatively, those with loads of miles to spare can opt to redeem Categories 1 to 4 concert tickets using their miles via KrisFlyer Experiences from Oct 30. Tickets from Categories 1 to 4 may be redeemed with 49,000; 38,000; 29,000 and 19,000 miles, respectively.\n",
      "\n",
      "General sale will commence from 11am on Oct 31.\n",
      "----------------------------------------------------------------\n",
      "Tickets for KrisFlyer and SIA Group's Category 1 to 4 concert tickets are to be redeemed at the end of the year.\n"
     ]
    }
   ],
   "source": [
    "text_to_summarise = \"\"\"Get ready to look perfect as you're thinking out loud on Feb 16, 2024 at Ed Sheeran's concert. The Grammy Award-winning singer is heading to Singapore for a one-night show at the National Stadium. Plus, he's bringing along English singer Calum Scott as a guest.\n",
    "\n",
    "Tickets for the concert will cost between S$88 and S$488 and can be purchased via Ticketmaster and at SingPost outlets.\n",
    "\n",
    "If you signed up for a UOB card for Taylor Swift's concert and didn't cancel your membership afterward, here's some great news. UOB cardholders can enjoy a presale from 10am on Oct 27 till 9.59 am on Oct 29.\n",
    "\n",
    "A second presale will be held for KrisFlyer members from 10am on Oct 30 to 9.59am on Oct 31. To get in on this presale, KrisFlyer UOB credit and debit cardholders will need to subscribe to receive KrisFlyer and SIA Group promotional emails via their KrisFlyer account preferences. They will then receive a unique access code from KrisFlyer via email on Oct 27. \n",
    "\n",
    "Members who are not KrisFlyer UOB credit or debit cardholders can download Kris+, the SIA Group’s lifestyle rewards app and spend 150 miles between Oct 20 and 25 to redeem a unique access code. Do note that redemptions are limited to the first 110,000 customers.\n",
    "\n",
    "Alternatively, those with loads of miles to spare can opt to redeem Categories 1 to 4 concert tickets using their miles via KrisFlyer Experiences from Oct 30. Tickets from Categories 1 to 4 may be redeemed with 49,000; 38,000; 29,000 and 19,000 miles, respectively.\n",
    "\n",
    "General sale will commence from 11am on Oct 31.\"\"\"\n",
    "\n",
    "print(text_to_summarise)\n",
    "print('----------------------------------------------------------------')\n",
    "\n",
    "result = summarizer_load_inf(text_to_summarise,\n",
    "                    min_length=MIN_TARGET_LENGTH,\n",
    "                    max_length=MAX_TARGET_LENGTH)\n",
    "\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0. Conclusion\n",
    "\n",
    "Our methodology of using pre-trained T5 models and fine-tuning them on the supervised tasks of of news summarisation has shown rather decent summaries of the 3 given news articles - article1, articel2, and articel3. Article1 missed capturing celebrity details, but there was notable agreements between article2 and article3, and their respective news summarisation. All these was achieved with 3 training epochs and fine-tuning a small T5 model on AWS EC2.\n",
    "\n",
    "However, the average ROUGE-L score of 0.20 is considered low which means there is a smaller overlap of words. This suggests that there are further ways to improve upon the existing model. Some ways to improve the model is using a bigger T5 model, adjusting the learning rate, letting the model train over more epochs on the entire training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
